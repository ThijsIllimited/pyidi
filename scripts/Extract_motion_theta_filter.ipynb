{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thijsmas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/thijsmas/HSC - Ladisk\\0_nad_1.cihx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thijsmas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pyMRAW.py:103: UserWarning: Clipped footage! (Total frame: 40000, Original total frame: 77663)\n",
      "  warnings.warn('Clipped footage! (Total frame: {}, Original total frame: {})'.format(cih['Total Frame'], cih['Original Total Frame'] ))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Date': '2021/6/21',\n",
       " 'Camera Type': 'FASTCAM SA-Z type 2100K-M-64GB',\n",
       " 'Record Rate(fps)': 20000.0,\n",
       " 'Shutter Speed(s)': 20664.0,\n",
       " 'Total Frame': 40000,\n",
       " 'Original Total Frame': 77663,\n",
       " 'Image Width': 768,\n",
       " 'Image Height': 768,\n",
       " 'File Format': 'Mraw',\n",
       " 'EffectiveBit Depth': 12,\n",
       " 'EffectiveBit Side': 'Higher',\n",
       " 'Color Bit': 16,\n",
       " 'Comment Text': ''}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Feature_selecter import FeatureSelecter\n",
    "from EMA_functions import *\n",
    "import matplotlib.animation as animation\n",
    "import pickle as pkl\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "file_name = \"0_nad_1.cihx\" #\"measurement_0_00_degres\" #\"Full_web_ecc2_new_Floc7_v0\"        #\"0_nad_1.cihx\"   # Second attempt, ecc2\n",
    "EMA_structure = EMA_Structure(file_name)\n",
    "video = EMA_structure.open_video(add_extension = False)\n",
    "reference_image = (0, 100)#(0, 100)\n",
    "bit_depth = 16\n",
    "\n",
    "fig, ax = EMA_structure.plot_still_frame(video, reference_image)\n",
    "mean_image = EMA_structure.mean_image\n",
    "mean_image /= np.max(mean_image)\n",
    "ani = EMA_structure.play_video(video, frame_range=range(200, 240))\n",
    "video.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel = [690, 165]\n",
    "# n = 11\n",
    "# image0  = np.array(video.mraw[100])\n",
    "# window0 = image0[pixel[1]-n//2:pixel[1]+n//2+1, pixel[0]-n//2:pixel[0]+n//2+1]\n",
    "# image1  = np.array(video.mraw[101])\n",
    "# window1 = image1[pixel[1]-n//2:pixel[1]+n//2+1, pixel[0]-n//2:pixel[0]+n//2+1]\n",
    "# Ii, Ij = np.gradient(window0)\n",
    "# Ix = Ij\n",
    "# Iy = -Ii\n",
    "# It = window1 - window0\n",
    "# # IxIx = Ix*Ix\n",
    "# # IyIy = Iy*Iy\n",
    "# # IxIy = Ix*Iy\n",
    "# # IxIt = Ix*It\n",
    "# # IyIt = Iy*It\n",
    "# Vx, Vy = np.zeros((n,n)), np.zeros((n,n))\n",
    "# for pixel_i in range(n):\n",
    "#     for pixel_j in range(n):\n",
    "#         IxIx    = Ix[pixel_i, pixel_j]**2\n",
    "#         IyIy    = Iy[pixel_i, pixel_j]**2\n",
    "#         IxIy    = Ix[pixel_i, pixel_j]*Iy[pixel_i, pixel_j]\n",
    "#         IxIt    = Ix[pixel_i, pixel_j]*It[pixel_i, pixel_j]\n",
    "#         IyIt    = Iy[pixel_i, pixel_j]*It[pixel_i, pixel_j]\n",
    "#         ATA = np.array([[IxIx, IxIy], [IxIy, IyIy]])\n",
    "#         ATAinv = np.linalg.inv(ATA)\n",
    "#         # denom = IxIx*IyIy - IxIy**2\n",
    "#         # if denom == 0:\n",
    "#         #     continue\n",
    "#         # ATAinv = 1/denom * np.array([[IyIy, -IxIy], [-IxIy, IxIx]])\n",
    "#         Vx[pixel_i, pixel_j], Vy[pixel_i, pixel_j] = -ATAinv @ np.array([IxIt, IyIt])\n",
    "# X, Y = np.meshgrid(range(n), range(n))\n",
    "# fig, ax = plt.subplots(2,1)\n",
    "# ax[0].imshow(image0, cmap = \"gray\")\n",
    "# ax[0].plot(pixel[0], pixel[1], \"r+\")\n",
    "# ax[1].imshow(window1, cmap = \"gray\")\n",
    "# ax[1].quiver(X, Y, Vx, Vy, color = \"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_size = (11,11)\n",
    "im1 = np.mean(video.mraw[200:205,100:400,600:800], axis = 0)\n",
    "# im1 = video.mraw[200,100:400,600:800]\n",
    "# im1 = gaussian_filter(im1, 2)\n",
    "im2 = np.mean(video.mraw[210:215,100:400,600:800], axis = 0)\n",
    "# im2 = video.mraw[201,100:400,600:800]\n",
    "# im2 = gaussian_filter(im2, 2)\n",
    "feature_selecter = FeatureSelecter(im2)\n",
    "feature_selecter.set_gt(im1, im2)\n",
    "feature_selecter.set_filter_method('Vx', roi_size=roi_size)\n",
    "Vx = feature_selecter.apply_filter()\n",
    "feature_selecter.set_filter_method('Vy', roi_size=roi_size)\n",
    "Vy = feature_selecter.apply_filter()\n",
    "\n",
    "fig, ax = plt.subplots(1,5, figsize = (15,5))\n",
    "ax[0].imshow(im1, cmap = \"gray\")\n",
    "ax[1].imshow(im2, cmap = \"gray\")\n",
    "ax[2].imshow(feature_selecter.gx, cmap = \"gray\")\n",
    "ax[3].imshow(feature_selecter.gy, cmap = \"gray\")\n",
    "ax[4].imshow(feature_selecter.gt, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(range(0, video.mraw[0,100:400,600:800].shape[1]), range(0, video.mraw[0,100:400,600:800].shape[0]))\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(im2-im1, cmap='gray')\n",
    "ax.quiver(X, Y, Vx, Vy, color='r', scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available filter methods: eig0, eig1, harris, trigs, harmonic_mean, eig_theta, eig_theta_off, eig0_test, eig1_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thijsmas\\Documents\\GitHub\\pyidi\\Feature_selecter.py:236: NumbaPerformanceWarning: \u001b[1m\u001b[1m'@' is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))\u001b[0m\u001b[0m\n",
      "  ATA00 = pixel_list[::2] @ pixel_list[::2]  # equivalent to ATA[0, 0]\n",
      "c:\\Users\\thijsmas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydev_ipython\\qt_loaders.py:115: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "c:\\Users\\thijsmas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydev_ipython\\qt_loaders.py:120: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\\\Users\\\\thijsmas\\\\AppData\\\\Local\\\\anaconda3\\\\Lib\\\\site-packages\\\\PyQt5\\\\QtCore.pyd'>\n",
      "  imp.find_module('QtCore', mod.__path__)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\Users\\thijsmas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydev_ipython\\qt_loaders.py:121: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\\\Users\\\\thijsmas\\\\AppData\\\\Local\\\\anaconda3\\\\Lib\\\\site-packages\\\\PyQt5\\\\QtGui.pyd'>\n",
      "  imp.find_module('QtGui', mod.__path__)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\Users\\thijsmas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydev_ipython\\qt_loaders.py:122: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\\\Users\\\\thijsmas\\\\AppData\\\\Local\\\\anaconda3\\\\Lib\\\\site-packages\\\\PyQt5\\\\QtSvg.pyd'>\n",
      "  imp.find_module('QtSvg', mod.__path__)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "min_distance = 15\n",
    "roi_size_vec = [(3,3)]#, (5,5), (7,7), (9,9), (11,11)]\n",
    "top_n_points = 24\n",
    "feature_selecter = FeatureSelecter(mean_image)\n",
    "for roi_size in roi_size_vec:\n",
    "    feature_selecter.set_filter_method('eig0', roi_size=roi_size)\n",
    "    scores = feature_selecter.apply_filter(downsample=1)\n",
    "    points = feature_selecter.pick_max_filter(min_distance=min_distance, top_n_points = top_n_points)\n",
    "    video.set_points(points)\n",
    "    video.show_points()\n",
    "    video.set_method('lk')\n",
    "    video.method.configure(reference_image = reference_image, roi_size= roi_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_size = (3,3)\n",
    "min_distance = 15\n",
    "threshold_percentage = 80\n",
    "feature_selecter = FeatureSelecter(mean_image)\n",
    "feature_selecter.set_filter_method('eig0', roi_size=roi_size)\n",
    "score_eig0_33 = feature_selecter.apply_filter(downsample=1)\n",
    "points_eig0_33 = feature_selecter.pick_max_filter(min_distance=min_distance, threshold_percentage=threshold_percentage)\n",
    "\n",
    "feature_selecter.set_theta(90)\n",
    "feature_selecter.set_filter_method('eig_theta', roi_size=roi_size)\n",
    "score_eig90_33 = feature_selecter.apply_filter(downsample=1)\n",
    "points_eig90_33 = feature_selecter.pick_max_filter(min_distance=min_distance, threshold_percentage=threshold_percentage)\n",
    "\n",
    "feature_selecter.set_theta(0)\n",
    "feature_selecter.set_filter_method('eig_theta', roi_size=roi_size)\n",
    "score_eig0_33 = feature_selecter.apply_filter(downsample=1)\n",
    "points_eig_0_33 = feature_selecter.pick_max_filter(min_distance=min_distance, threshold_percentage=threshold_percentage)\n",
    "\n",
    "roi_size = (5,5)\n",
    "feature_selecter.set_filter_method('eig0', roi_size=roi_size)\n",
    "score_eig0_55 = feature_selecter.apply_filter(downsample=1)\n",
    "points_eig0_55 = feature_selecter.pick_max_filter(min_distance=min_distance, threshold_percentage=threshold_percentage)\n",
    "\n",
    "feature_selecter.set_theta(90)\n",
    "feature_selecter.set_filter_method('eig_theta', roi_size=roi_size)\n",
    "score_eig90_55 = feature_selecter.apply_filter(downsample=1)\n",
    "points_eig90_55 = feature_selecter.pick_max_filter(min_distance=min_distance, threshold_percentage=threshold_percentage)\n",
    "\n",
    "feature_selecter.set_theta(0)\n",
    "feature_selecter.set_filter_method('eig_theta', roi_size=roi_size)\n",
    "score_eig0_55 = feature_selecter.apply_filter(downsample=1)\n",
    "points_eig_0_55 = feature_selecter.pick_max_filter(min_distance=min_distance, threshold_percentage=threshold_percentage)\n",
    "\n",
    "roi_size = (11,11)\n",
    "min_distance = 11\n",
    "threshold_percentage = 70\n",
    "feature_selecter = FeatureSelecter(mean_image)\n",
    "feature_selecter.set_filter_method('eig0', roi_size=roi_size)\n",
    "score_eig0_1111 = feature_selecter.apply_filter(downsample=1)\n",
    "points_eig0_1111 = feature_selecter.pick_max_filter(min_distance=min_distance, threshold_percentage=threshold_percentage)\n",
    "video.set_points(points_eig0_1111)\n",
    "video.show_points()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_size = (11,11)\n",
    "min_distance = 11\n",
    "threshold_percentage = 50\n",
    "feature_selecter = FeatureSelecter(mean_image)\n",
    "feature_selecter.set_filter_method('eig0', roi_size=roi_size)\n",
    "score_eig0_1111 = feature_selecter.apply_filter(downsample=1)\n",
    "points_eig0_1111 = feature_selecter.pick_max_filter(min_distance=min_distance, threshold_percentage=threshold_percentage)\n",
    "video.set_points(points_eig0_1111)\n",
    "video.show_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.set_method('lk')\n",
    "video.method.configure(reference_image = reference_image, roi_size= roi_size, mraw_range=(1, 1000))\n",
    "d_eig0_1111 = video.get_displacements(processes = 12)\n",
    "pickle_file_path = \"d_eig0_1111.pkl\"\n",
    "with open(pickle_file_path, \"wb\") as file:\n",
    "    pkl.dump((points_eig0_1111,d_eig0_1111), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.set_points(points_eig0_33)\n",
    "video.show_points()\n",
    "video.set_points(points_eig90_33)\n",
    "video.show_points()\n",
    "video.set_points(points_eig_0_33)\n",
    "video.show_points()\n",
    "video.set_points(points_eig0_55)\n",
    "video.show_points()\n",
    "video.set_points(points_eig90_55)\n",
    "video.show_points()\n",
    "video.set_points(points_eig_0_55)\n",
    "video.show_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extact motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video.set_method('lk')\n",
    "video.method.configure(reference_image = reference_image, roi_size= (3, 3))\n",
    "\n",
    "video.set_points(points_eig0_33)\n",
    "d_eig0_33 = video.get_displacements(processes = 12)\n",
    "pickle_file_path = \"d_eig0_33.pkl\"\n",
    "with open(pickle_file_path, \"wb\") as file:\n",
    "    pkl.dump((points_eig0_33,d_eig0_33), file)\n",
    "\n",
    "video.set_points(points_eig90_33)\n",
    "d_eig90_33 = video.get_displacements(processes = 12)\n",
    "pickle_file_path = \"d_eig90_33.pkl\"\n",
    "with open(pickle_file_path, \"wb\") as file:\n",
    "    pkl.dump((points_eig90_33, d_eig90_33), file)\n",
    "\n",
    "video.set_points(points_eig_0_33)\n",
    "d_eig_0_33 = video.get_displacements(processes = 12)\n",
    "pickle_file_path = \"d_eig_0_33.pkl\"\n",
    "with open(pickle_file_path, \"wb\") as file:\n",
    "    pkl.dump((points_eig_0_33,d_eig_0_33), file)\n",
    "\n",
    "video.method.configure(reference_image = reference_image, roi_size= (5, 5))\n",
    "video.set_points(points_eig0_55)\n",
    "d_eig0_55 = video.get_displacements(processes = 12)\n",
    "pickle_file_path = \"d_eig0_55.pkl\"\n",
    "with open(pickle_file_path, \"wb\") as file:\n",
    "    pkl.dump((points_eig0_55, d_eig0_55), file)\n",
    "\n",
    "video.set_points(points_eig90_55)\n",
    "d_eig90_55 = video.get_displacements(processes = 12)\n",
    "pickle_file_path = \"d_eig90_55.pkl\"\n",
    "with open(pickle_file_path, \"wb\") as file:\n",
    "    pkl.dump((points_eig90_55, d_eig90_55), file)\n",
    "\n",
    "video.set_points(points_eig_0_55)\n",
    "d_eig_0_55 = video.get_displacements(processes = 12)\n",
    "pickle_file_path = \"d_eig_0_55.pkl\"\n",
    "with open(pickle_file_path, \"wb\") as file:\n",
    "    pkl.dump((points_eig_0_55, d_eig_0_55), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# valid_points_eig0_33 = (np.max(d_eig0_33, axis = (1, 2)) > .01) & (np.max(d_eig0_33, axis = (1, 2)) < 20)\n",
    "# tp_eig0_33 = points_eig0_33[:, np.newaxis,:] + d_eig0_33\n",
    "# EMA_structure.play_video(video, frame_range=range(1, 1000), points=tp_eig0[valid_points_eig0_33])\n",
    "\n",
    "# valid_points_eig0_55 = (np.max(d_eig0_55, axis = (1, 2)) > .01) & (np.max(d_eig0_55, axis = (1, 2)) < 20)\n",
    "# tp_eig0_55 = points_eig0_55[:, np.newaxis,:] + d_eig0_55\n",
    "# EMA_structure.play_video(video, frame_range=range(1, 1000), points=tp_eig0_55[valid_points_eig0_55])\n",
    "\n",
    "valid_points_eig0_1111 = (np.max(d_eig0_1111, axis = (1, 2)) > .01) & (np.max(d_eig0_1111, axis = (1, 2)) < 20)\n",
    "tp_eig0_1111 = points_eig0_1111[:, np.newaxis,:] + d_eig0_1111\n",
    "EMA_structure.play_video(video, frame_range=range(1, 1000), points=tp_eig0_1111[valid_points_eig0_1111])\n",
    "\n",
    "# valid_points_eigth = (np.max(d_eigth, axis = (1, 2)) > 1) & (np.max(d_eigth, axis = (1, 2)) < 20)\n",
    "# tp_eigth = points_eigth[::5][:, np.newaxis,:] + d_eigth\n",
    "# EMA_structure.play_video(video, frame_range=range(1, 1000), points=tp_eigth[valid_points_eigth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fps = video.info['Record Rate(fps)']\n",
    "t_vec = np.arange(1, 1000)/fps\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t_vec, (d_eig0[valid_points_eig0, :, 0][::5,:]).T)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Magnitude (pixels)')\n",
    "ax.set_title('Magnitude of Displacements')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t_vec, (d_eigth[valid_points_eigth, :, 0][::5,:]).T)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Magnitude (pixels)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('d_eig0_33.pkl', 'rb') as file:\n",
    "    d_eig0_33 = pkl.load(file)\n",
    "with open('d_eig90_33.pkl', 'rb') as file:\n",
    "    d_eig90_33 = pkl.load(file)\n",
    "with open('d_eig_0_33.pkl', 'rb') as file:\n",
    "    d_eig_0_33 = pkl.load(file)\n",
    "with open('d_eig0_55.pkl', 'rb') as file:\n",
    "    d_eig0_55 = pkl.load(file)\n",
    "with open('d_eig90_55.pkl', 'rb') as file:\n",
    "    d_eig90_55 = pkl.load(file)\n",
    "with open('d_eig_0_55.pkl', 'rb') as file:\n",
    "    d_eig_0_55 = pkl.load(file)\n",
    "steps = 100\n",
    "fps = video.info['Record Rate(fps)']\n",
    "ylim = .250\n",
    "xlim = .05\n",
    "t_vec = np.arange(d_eig0_55.shape[1])/fps\n",
    "fig, ax = plt.subplots(5,1, figsize = (15, 10))\n",
    "ax[0].plot(t_vec, d_eig0_33[::steps,:,1].T)\n",
    "ax[0].set_title('Eig0 3x3')\n",
    "ax[1].plot(t_vec, d_eig90_33[::steps,:,1].T)\n",
    "ax[1].set_title('Eig theta 90 3x3')\n",
    "ax[2].plot(t_vec, d_eig_0_33[::steps,:,1].T)\n",
    "ax[2].set_title('Eig theta 0 3x3')\n",
    "ax[3].plot(t_vec, d_eig0_55[::steps,:,1].T)\n",
    "ax[3].set_title('Eig0 5x5')\n",
    "ax[4].plot(t_vec, d_eig90_55[::steps,:,1].T)\n",
    "ax[4].set_title('Eig theta 90 5x5')\n",
    "for ax_i in ax:\n",
    "    ax_i.set_ylim(-ylim, ylim)\n",
    "    ax_i.set_xlim(0, xlim)\n",
    "    ax_i.set_xlabel('Time (s)')\n",
    "    ax_i.set_ylabel('Magnitude (pixels)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = video.info['Record Rate(fps)']\n",
    "t_vec = np.arange(d_eig0_1111.shape[1])/fps\n",
    "n = d_eig0_1111.shape[1]\n",
    "Freq = np.fft.rfftfreq(n, 1/fps)\n",
    "Disp_FFT = np.fft.rfft(d_eig0_1111[:,:,1], n=n) / n\n",
    "Acquisition_period  = t_vec[-1]\n",
    "S_xx = 1/Acquisition_period * np.conj(Disp_FFT) * Disp_FFT\n",
    "z_scores = (np.mean(S_xx, axis=1) - np.mean(S_xx)) / np.std(S_xx, axis=1)\n",
    "threshold = 1\n",
    "valid = np.abs(z_scores) < threshold\n",
    "print('n excluded: ', np.sum(~valid))\n",
    "S_xx = S_xx[valid]\n",
    "\n",
    "S_xx_mean = np.mean(S_xx, axis = 0)\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(Freq, S_xx.T,'k-', alpha = .5, lw = 0.2)\n",
    "ax.semilogy(Freq, S_xx_mean,'r-')\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Sxx (pixels^2/Hz)')\n",
    "ax.set_xlim(0, 1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
