{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "import numpy as np              # Python's standard numerical library\n",
    "import matplotlib.pyplot as plt # Python's scientific visualization library\n",
    "from pyidi import ROISelect\n",
    "from matplotlib.path import Path\n",
    "import pickle as pk\n",
    "from pixel_setter import play_video\n",
    "from scipy.ndimage import uniform_filter\n",
    "from EMA_functions import *\n",
    "from DIC_functions import *\n",
    "from Feature_selecter import *\n",
    "root_drive_sim = os.path.normpath('G:/.shortcut-targets-by-id/1k1B8zPb3T8H7y6x0irFZnzzmfQPHMRPx/Illimited Lab Projects/Research Projects/Spiders/Simulations')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name =  '1mm_meritev_1_nasproti_1_3g_RMS_1s.cih'\n",
    "root_video = 'D:/thijsmas/HSC - Ladisk/transfer_104353_files_9c630a94'\n",
    "file_path = os.path.join(root_video, file_name)\n",
    "# file_name = 'measurement_0_00_degres_S01.cihx'\n",
    "EMA_structure = EMA_Structure(file_name)\n",
    "video = EMA_structure.open_video(add_extension=False)\n",
    "video.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sequential_image_n = 0\n",
    "still_image = video.mraw[sequential_image_n]\n",
    "\n",
    "fig, ax = EMA_structure.plot_still_frame(video, sequential_image_n, show_saturation=False, bit_depth = 16)\n",
    "# fig.savefig(os.path.join(root_drive_sim, 'still images', f'{file_name}_frame_sat0.png'), dpi=300, bbox_inches='tight')\n",
    "# plt.close(fig)\n",
    "\n",
    "fig, ax = EMA_structure.plot_still_frame(video, sequential_image_n, show_saturation=True, bit_depth = 16)\n",
    "# fig.savefig(os.path.join(root_drive_sim, 'still images','with saturation', f'{file_name}_frame_sat1.png'), dpi=300, bbox_inches='tight')\n",
    "# plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_select = ROISelect(video)\n",
    "roi_select.polygon\n",
    "polygon_new = np.array(roi_select.polygon)\n",
    "\n",
    "polygon_group0 = np.array([[409, 695, 531, 247, 409],\n",
    "                            [321, 320, 637, 585, 321]])\n",
    "polygon_group1 = np.array([[409, 693, 522, 231, 409],\n",
    "                            [321, 322,  20,  73, 321]])\n",
    "polygon_group2 = np.array([[232, 409, 247,  18, 232],\n",
    "                            [ 75, 321, 586, 340,  75]])\n",
    "polygon = np.array([[231,  17, 244, 530, 693, 523, 231],\n",
    "                     [ 72, 339, 586, 638, 321,  20,  72]])\n",
    "\n",
    "path = Path(polygon.T)\n",
    "path_group0 = Path(polygon_group0.T)\n",
    "path_group1 = Path(polygon_group1.T)\n",
    "path_group2 = Path(polygon_group2.T)\n",
    "paths_1d = [path_group0, path_group1, path_group2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_right = polygon_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0, 693, 693,   4,   0],\n",
       "        [314, 321,   4,   1, 314]]),\n",
       " array([[689,  11,   9, 692, 689],\n",
       "        [324, 328, 634, 634, 324]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_left, poly_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "first_frame = 1\n",
    "ani = play_video(video, range(first_frame,video.N - 1), interval=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# reference_image = (3000, 8000)\n",
    "# reference_image = (120, video.N)\n",
    "# mean_image      = np.mean(video.mraw[reference_image[0]:reference_image[1]], axis=0)\n",
    "# frame_0 = video.mraw[0]\n",
    "# mean_image_fft = np.fft.fft2(mean_image)\n",
    "# frame_0_fft = np.fft.fft2(frame_0)\n",
    "# diff_img = np.abs(mean_image-frame_0)\n",
    "# diff_img_fft = np.abs(mean_image_fft-frame_0_fft)\n",
    "\n",
    "# fig, ax = plt.subplots(3,2)\n",
    "# ax[0,0].imshow(np.abs(mean_image), cmap='gray')\n",
    "# ax[0,1].imshow(np.abs(frame_0), cmap='gray')\n",
    "# ax[1,0].imshow(np.abs(mean_image_fft), cmap='gray', vmax = 1e7, vmin = 1e5)\n",
    "# ax[1,1].imshow(np.abs(frame_0_fft), cmap='gray', vmax = 1e7, vmin = 1e5)\n",
    "# ax[2,0].imshow(diff_img, cmap='gray')\n",
    "# ax[2,1].imshow(np.abs(diff_img_fft), cmap='gray', vmax = 1e7, vmin = 1e5)\n",
    "\n",
    "# np.save('mean_image_inverted_cube2.npy', mean_image)\n",
    "mean_image = np.load('mean_image_inverted_cube2.npy')\n",
    "# diff_img  = np.abs(mean_image-video.mraw[0])\n",
    "# Gx, Gy = np.gradient(mean_image)\n",
    "\n",
    "# min_Gx = np.min(np.abs(Gx))\n",
    "# max_Gx = np.max(np.abs(Gx))\n",
    "# min_Gy = np.min(np.abs(Gy))\n",
    "# max_Gy = np.max(np.abs(Gy))\n",
    "# mask = (Gx > 0.1*max_Gx) & (Gy > 0.1*max_Gy)\n",
    "# angle_pic = np.nan * np.ones_like(Gx)\n",
    "# angle_pic[mask] = np.arctan(Gy[mask]/Gx[mask])\n",
    "\n",
    "# fig, ax = plt.subplots(2,2)\n",
    "# ax[0,0].imshow(mean_image, cmap='gray')\n",
    "# # ax[1,0].imshow(diff_img, cmap='gray')\n",
    "# ax[0,1].imshow(np.abs(Gx), cmap='gray')\n",
    "# ax[1,1].imshow(np.abs(Gy), cmap='gray')\n",
    "# ax[1,1].imshow(angle_pic, cmap='gray')\n",
    "\n",
    "# min_Gx, max_Gx, min_Gy, max_Gy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set points 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_depth = 16\n",
    "roi_size  = (9,9)\n",
    "\n",
    "mask_image = path.contains_points(np.array([(i,j) for i in range(mean_image.shape[0]) for j in range(mean_image.shape[1])]))\n",
    "mask_image = mask_image.reshape(mean_image.shape)\n",
    "mean_image_masked = np.copy(mean_image)\n",
    "# mean_image_masked[~mask_image] = np.nan\n",
    "mean_image_masked[still_image >= int(0.99*(2**bit_depth-1))] = np.nan\n",
    "# mean_image_masked[mean_image_masked > 2**16-20] = np.nan\n",
    "\n",
    "n_tracking_points = 26820\n",
    "feature_selecter = FeatureSelecter(mean_image_masked)\n",
    "feature_selecter.set_filter_method('eig0', roi_size)\n",
    "score_full = feature_selecter.apply_filter(downsample=1)\n",
    "score_full[~mask_image] = 0\n",
    "# maxima2d = feature_selecter.pick_max_filter(score_image = score_full, min_distance = roi_size, absolute_treshold = 0.0) #, top_n_points = n_tracking_points\n",
    "# maxima2d = feature_selecter.pick_ANMS(score_image = score_full, n_points=n_tracking_points, c_robust=0.05)  \n",
    "maxima2d = feature_selecter.pick_max_loop(score_image = score_full, min_distance = (3,3), n_points = n_tracking_points, minimum_score= 10)\n",
    "feature_selecter.plot_score_image(maxima=False)\n",
    "\n",
    "video.set_method('lk')\n",
    "video.method.configure(roi_size = roi_size, reference_image = mean_image, resume_analysis=False) #, mraw_range=(1, 1000)\n",
    "video.set_points(maxima2d)\n",
    "displacement = video.get_displacements(processes = 24)\n",
    "video.show_points()\n",
    "len(maxima2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set points 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available filter methods: eig0, eig1, harris, trigs, harmonic_mean, eig_theta, eig_theta_off, eig0_test, eig1_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thijsmas\\Documents\\GitHub\\pyidi\\pyidi\\methods\\_directional_lucas_kanade.py:124: UserWarning: The direction vector d must have a norm of 1. The input vector was normalized.\n",
      "  warnings.warn('The direction vector d must have a norm of 1. The input vector was normalized.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roi_size: (3, 3), smoothing_subset: (1, 1), s: [0.44759716 0.89423531]\n",
      "roi_size: (3, 3), smoothing_subset: (3, 3), s: [0.44759716 0.89423531]\n",
      "skipping\n",
      "Available filter methods: eig0, eig1, harris, trigs, harmonic_mean, eig_theta, eig_theta_off, eig0_test, eig1_test\n",
      "roi_size: (5, 5), smoothing_subset: (1, 1), s: [0.44759716 0.89423531]\n",
      "roi_size: (5, 5), smoothing_subset: (3, 3), s: [0.44759716 0.89423531]\n",
      "roi_size: (5, 5), smoothing_subset: (5, 5), s: [0.44759716 0.89423531]\n",
      "Available filter methods: eig0, eig1, harris, trigs, harmonic_mean, eig_theta, eig_theta_off, eig0_test, eig1_test\n",
      "roi_size: (7, 7), smoothing_subset: (1, 1), s: [0.44759716 0.89423531]\n",
      "roi_size: (7, 7), smoothing_subset: (3, 3), s: [0.44759716 0.89423531]\n",
      "roi_size: (7, 7), smoothing_subset: (5, 5), s: [0.44759716 0.89423531]\n",
      "Available filter methods: eig0, eig1, harris, trigs, harmonic_mean, eig_theta, eig_theta_off, eig0_test, eig1_test\n",
      "roi_size: (9, 9), smoothing_subset: (1, 1), s: [0.44759716 0.89423531]\n",
      "roi_size: (9, 9), smoothing_subset: (3, 3), s: [0.44759716 0.89423531]\n",
      "roi_size: (9, 9), smoothing_subset: (5, 5), s: [0.44759716 0.89423531]\n",
      "Available filter methods: eig0, eig1, harris, trigs, harmonic_mean, eig_theta, eig_theta_off, eig0_test, eig1_test\n",
      "roi_size: (11, 11), smoothing_subset: (1, 1), s: [0.44759716 0.89423531]\n",
      "roi_size: (11, 11), smoothing_subset: (3, 3), s: [0.44759716 0.89423531]\n",
      "roi_size: (11, 11), smoothing_subset: (5, 5), s: [0.44759716 0.89423531]\n",
      "skipping\n",
      "Available filter methods: eig0, eig1, harris, trigs, harmonic_mean, eig_theta, eig_theta_off, eig0_test, eig1_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thijsmas\\Documents\\GitHub\\pyidi\\pyidi\\methods\\_directional_lucas_kanade.py:124: UserWarning: The direction vector d must have a norm of 1. The input vector was normalized.\n",
      "  warnings.warn('The direction vector d must have a norm of 1. The input vector was normalized.')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m video\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mconfigure(roi_size \u001b[38;5;241m=\u001b[39m roi_size, dyx \u001b[38;5;241m=\u001b[39m s, reference_image \u001b[38;5;241m=\u001b[39m mean_image,  resume_analysis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, smoothing_size \u001b[38;5;241m=\u001b[39m smoothing_subset, mraw_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m120\u001b[39m, video\u001b[38;5;241m.\u001b[39mN \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# video.method.configure(roi_size = roi_size, dxy = np.array([s[1], s[0]]), subset_size = smoothing_subset, reference_image = mean_image, resume_analysis=False) #, mraw_range=(1, 1000), subset_size = 3,          \u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroi_size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroi_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, smoothing_subset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msmoothing_subset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, s: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m video\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mconfigure(roi_size \u001b[38;5;241m=\u001b[39m roi_size, dyx \u001b[38;5;241m=\u001b[39m s, reference_image \u001b[38;5;241m=\u001b[39m mean_image,  resume_analysis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, smoothing_size \u001b[38;5;241m=\u001b[39m smoothing_subset, mraw_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m120\u001b[39m, video\u001b[38;5;241m.\u001b[39mN \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# video.method.configure(roi_size = roi_size, dxy = np.array([s[1], s[0]]), subset_size = smoothing_subset, reference_image = mean_image, resume_analysis=False) #, mraw_range=(1, 1000), subset_size = 3,          \u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroi_size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroi_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, smoothing_subset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msmoothing_subset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, s: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\thijsmas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thijsmas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "s_vec = np.array([[0.44759716, 0.89423531], [-0.55271155,  0.83337263], [-0.96837048,  0.24951675]]) # i,j format!\n",
    "n_tracking_points       = int(n_tracking_points/3)\n",
    "roi_size_vec            = [(3,3), (5,5),(7,7), (9,9), (11,11)]  #\n",
    "smoothing_subset_vec    = [(1, 1), (3,3), (5,5)]\n",
    "\n",
    "mean_image_masked = np.copy(mean_image)\n",
    "Gi, Gj = np.gradient(mean_image_masked)\n",
    "\n",
    "for s, path in zip(s_vec, paths_1d):\n",
    "    if s[0] == s_vec[1][0]:\n",
    "        print('skipping')\n",
    "    Gs  = np.abs(s[1]*Gi + s[0]*Gj)\n",
    "    mask_image = path.contains_points(np.array([(i,j) for i in range(mean_image.shape[0]) for j in range(mean_image.shape[1])])).reshape(mean_image.shape)\n",
    "    mask_image = mask_image.reshape(mean_image.shape)\n",
    "    for roi_size in roi_size_vec:\n",
    "        filtered_image = uniform_filter(Gs, size=roi_size[0])\n",
    "        filtered_image[~mask_image] = 0\n",
    "        filtered_image[still_image >= int(0.99*(2**bit_depth-1))] = 0\n",
    "        feature_selecter = FeatureSelecter(filtered_image)\n",
    "\n",
    "        # maxima1d = feature_selecter.pick_max_filter(score_image = filtered_image, min_distance = roi_size[0], absolute_treshold = None, threshold_percentage = 0, top_n_points = n_tracking_points)\n",
    "        # maxima1d = feature_selecter.pick_ANMS(score_image = filtered_image, n_points=n_tracking_points, c_robust=0.05)\n",
    "        maxima1d = feature_selecter.pick_max_loop(score_image = filtered_image, min_distance = (9,9), n_points = n_tracking_points, minimum_score= 10)\n",
    "\n",
    "        feature_selecter.score_image = filtered_image\n",
    "        # feature_selecter.plot_score_image(maxima=True)\n",
    "        video.set_method('lk_1D')\n",
    "        video.set_points(maxima1d)\n",
    "\n",
    "        video.info['Direction'] = s.tolist()\n",
    "        video.info['Polygon'] = path.vertices.tolist()\n",
    "\n",
    "        for smoothing_subset in smoothing_subset_vec:\n",
    "            if roi_size[0] - smoothing_subset[0] < 0:\n",
    "                print('skipping')\n",
    "                continue\n",
    "            video.method.configure(roi_size = roi_size, dyx = s, reference_image = mean_image,  resume_analysis=False, smoothing_size = smoothing_subset, mraw_range=(120, video.N -1))\n",
    "            # video.method.configure(roi_size = roi_size, dxy = np.array([s[1], s[0]]), subset_size = smoothing_subset, reference_image = mean_image, resume_analysis=False) #, mraw_range=(1, 1000), subset_size = 3,          \n",
    "            print(f'roi_size: {roi_size}, smoothing_subset: {smoothing_subset}, s: {s}')\n",
    "            # displacement_1d = video.get_displacements(processes=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thijsmas\\AppData\\Local\\Temp\\ipykernel_16408\\637333002.py:3: PendingDeprecationWarning: The set_tight_layout function will be deprecated in a future version. Use set_layout_engine instead.\n",
      "  fig.set_tight_layout(True)\n"
     ]
    }
   ],
   "source": [
    "score_list = filtered_image[maxima1d[:, 0], maxima1d[:, 1]]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 7.5))\n",
    "fig.set_tight_layout(True)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.imshow(mean_image, cmap='gray')\n",
    "ax.scatter(maxima1d[:,1], maxima1d[:,0], marker='o',s=10, c=score_list, cmap='RdYlGn')\n",
    "ax.plot(polygon[1], polygon[0], color='k', lw=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_vec_loaded = np.load('s_vec.npy')\n",
    "s_vec_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "s_vec = np.array([[0.44759716, 0.89423531], [-0.55271155,  0.83337263], [-0.96837048,  0.24951675]]) # i,j format!\n",
    "# n_tracking_points = 2682\n",
    "n_tracking_points = 24\n",
    "# n_tracking_points       = int(n_tracking_points/3)\n",
    "\n",
    "roi_size = (15,15)\n",
    "smoothing_size = (3,3)\n",
    "s = s_vec[0]\n",
    "path = paths_1d[0]\n",
    "\n",
    "mask_image = path_group0.contains_points(np.array([(i,j) for i in range(mean_image.shape[0]) for j in range(mean_image.shape[1])])).reshape(mean_image.shape)\n",
    "mask_image = mask_image.reshape(mean_image.shape)\n",
    "\n",
    "mean_image_masked = np.copy(mean_image)\n",
    "Gi, Gj = np.gradient(mean_image_masked)\n",
    "Gs  = np.abs(s[0]*Gi + s[1]*Gj)\n",
    "    \n",
    "filtered_image = uniform_filter(Gs, size=roi_size)\n",
    "filtered_image[~mask_image] = 0\n",
    "filtered_image[mean_image_masked >= int(0.99*(2**bit_depth-1))] = 0\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(filtered_image, cmap='gray')\n",
    "feature_selecter = FeatureSelecter(filtered_image)\n",
    "\n",
    "feature_selecter.score_image = filtered_image\n",
    "# maxima1d = feature_selecter.pick_max_filter(score_image = filtered_image, min_distance = roi_size[0], absolute_treshold = None, threshold_percentage = 0, top_n_points = n_tracking_points)\n",
    "# maxima1d = feature_selecter.pick_ANMS(score_image = filtered_image, n_points=n_tracking_points, c_robust=0.05)\n",
    "maxima1d = feature_selecter.pick_max_loop(score_image = filtered_image, min_distance = (9,9), n_points = n_tracking_points, minimum_score= 1000)\n",
    "\n",
    "feature_selecter.plot_score_image(maxima=True)\n",
    "video.set_method('lk_1D')\n",
    "# video.set_method('lk')\n",
    "video.set_points(maxima1d)\n",
    "video.show_points()\n",
    "video.info['Direction'] = s.tolist()\n",
    "video.info['Polygon'] = path.vertices.tolist()\n",
    "\n",
    "video.method.configure(roi_size = roi_size, dyx = s, smoothing_size = smoothing_size, reference_image = mean_image, resume_analysis=False, max_nfev = 50, mraw_range=(121, 1121)) #, mraw_range=(3000, 8000), subset_size = 3,          \n",
    "# video.method.configure(roi_size = roi_size, dyx = s_vec_loaded, subset_size = smoothing_subset, reference_image = mean_image, resume_analysis=False, max_nfev = 50, mraw_range=(3000, 8000)) #, mraw_range=(1, 1000), subset_size = 3,          \n",
    "# video.method.configure(roi_size = roi_size, reference_image = mean_image, resume_analysis=False, max_nfev = 50, mraw_range=(3000, 8000)) #, mraw_range=(1, 1000), subset_size = 3,          \n",
    "print(f'roi_size: {roi_size}, smoothing_subset: {smoothing_size}, s: {s}')\n",
    "# displacement_1d = video.get_displacements(processes=1)\n",
    "displacement_1d = video.get_displacements(processes=24)\n",
    "\n",
    "scores  = filtered_image[maxima1d[:,0], maxima1d[:,1]]\n",
    "scores.min(), scores.max(), scores.mean(), scores.std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.set_method('lk_1D')\n",
    "d = (0,1)\n",
    "video.method.configure(roi_size = roi_size, d = d, reference_image = reference_image, resume_analysis=False) #, mraw_range=(1, 1000)\n",
    "video.set_points(maxima1d[mask_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacement_1d = video.get_displacements(processes=24)\n",
    "EMA_structure.displacements = displacement\n",
    "EMA_structure.maxima = maxima1d\n",
    "EMA_structure.mean_image = mean_image\n",
    "root = 'C:/Users/thijsmas/Documents/GitHub/pyidi_data/'\n",
    "path = os.path.join(root, 'EMA structure', file_name+f'_1d_roi{roi_size[0]}x{roi_size[1]}.pkl')\n",
    "with open(path, 'wb') as f:\n",
    "    pk.dump(EMA_structure, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_size_2d = (7,7)\n",
    "roi_size_1d = (3,3)\n",
    "reference_image = (0, 150)\n",
    "n_tracking_points_1d = 6000\n",
    "n_tracking_points_2D = 6000\n",
    "Polygon = Path(polygon.T)\n",
    "d = (0,1)\n",
    "s = np.array([0,1])\n",
    "root = 'C:/Users/thijsmas/Documents/GitHub/pyidi_data/'\n",
    "\n",
    "for path_c in path_list:\n",
    "    file_name = os.path.basename(path_c)\n",
    "    EMA_structure = EMA_Structure(file_name[:-5] + '.cih')\n",
    "    video = EMA_structure.open_video(add_extension=False)\n",
    "\n",
    "    mean_image      = np.mean(video.mraw[reference_image[0]:reference_image[1]], axis=0)\n",
    "\n",
    "    feature_selecter = FeatureSelecter(mean_image)\n",
    "    feature_selecter.set_filter_method('eig0', roi_size_2d)\n",
    "    score_full = feature_selecter.apply_filter(downsample=1)\n",
    "    maxima2d = feature_selecter.pick_max_filter(score_image = score_full, min_distance = roi_size_2d, absolute_treshold = 0.0) #, top_n_points = n_tracking_points\n",
    "    mask_points = Polygon.contains_points(maxima2d)\n",
    "\n",
    "    video.set_method('lk')\n",
    "    video.method.configure(roi_size = roi_size_2d, reference_image = reference_image, resume_analysis=False) #, mraw_range=(1, 1000)\n",
    "    video.set_points(maxima2d[mask_points])\n",
    "\n",
    "    displacement = video.get_displacements(processes = 24)\n",
    "    EMA_structure.displacements = displacement\n",
    "    EMA_structure.maxima = maxima2d[mask_points]\n",
    "    EMA_structure.mean_image = mean_image\n",
    "    \n",
    "    path = os.path.join(root, 'EMA structure', file_name+f'_2d_roi{roi_size_2d[0]}x{roi_size_2d[1]}.pkl')\n",
    "    with open(path, 'wb') as f:\n",
    "        pk.dump(EMA_structure, f)\n",
    "    \n",
    "    Gi, Gj = np.gradient(mean_image)\n",
    "    \n",
    "    Gs  = s[0]*Gj + s[1]*Gi\n",
    "    filtered_image = uniform_filter(Gs, size=roi_size_1d[0])\n",
    "    maxima1d = feature_selecter.pick_max_filter(score_image = Gi, min_distance = roi_size_1d[0], absolute_treshold = None, threshold_percentage = 0, top_n_points = n_tracking_points)\n",
    "\n",
    "    mask_points = Polygon.contains_points(maxima1d)\n",
    "    video.set_method('lk_1D')\n",
    "    video.method.configure(roi_size = roi_size_1d, d = d, reference_image = reference_image, resume_analysis=False) #, mraw_range=(1, 1000)\n",
    "    video.set_points(maxima1d[mask_points])\n",
    "\n",
    "    displacement = video.get_displacements(processes=24)\n",
    "    EMA_structure.displacements = displacement\n",
    "    EMA_structure.maxima = maxima1d[mask_points]\n",
    "    EMA_structure.mean_image = mean_image\n",
    "\n",
    "    path = os.path.join(root, 'EMA structure', file_name+f'_1d_roi{roi_size_1d[0]}x{roi_size_1d[1]}.pkl')\n",
    "    with open(path, 'wb') as f:\n",
    "        pk.dump(EMA_structure, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
